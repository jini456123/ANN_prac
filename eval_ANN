'''
simple test/train not the best for evaluation of model due to bias-variance tradeoff issue.
Use K-fold cross validation via keras & scikit_learn. It splits up training set into folds
of iteration. This method tests 2 things: whether this method's acc is far off from the 
original simple test/train acc we had previously. Next, we can evaluate variance of acc
'''

from keras.wrappers.sciket_learn import KerasClassifier
from sklearn.model_selection import cross_val_score

#build a function which will return the ANN classifier I built that will be applied to KerasClassifier

def build_classifier():
  classifier = Sequential()
  classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))
  classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))
  classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))
  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
  return classifier

classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, nb_epoch = 100)
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)
#here, n_jobs is important, as by setting it as -1, it runs "all CPUs", allowing the folds to run all
#at the same time, therefore reducing the time and speeding the process

#accuracies returned all acc results from keras classifier. compute mean to get mean acc,
#and variance to see how much each acc deviate from one another. Use these measure to improve ANN
mean = accuracies.mean()
variance = accuracies.std()
